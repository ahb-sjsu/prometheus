{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Prometheus Toolsuite - Interactive Tutorial\n",
    "\n",
    "**Codebase Fitness Analysis: Complexity √ó Resilience = Reliability**\n",
    "\n",
    "This notebook walks you through the Prometheus toolsuite for analyzing code quality and resilience patterns.\n",
    "\n",
    "## Tools Covered\n",
    "\n",
    "| Tool | Purpose | Output |\n",
    "|------|---------|--------|\n",
    "| **Prometheus** | Combined fitness analysis | Quadrant chart (Complexity vs Resilience) |\n",
    "| **Hubris** | Resilience theater detection | Pattern quality analysis |\n",
    "| **Aegis** (shield_analyzer) | Resilience pattern detection | Shield rating |\n",
    "| **Entropy Analyzer** | Complexity metrics | Risk assessment |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's make sure all the required files are in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all toolsuite files exist\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "required_files = [\n",
    "    \"prometheus.py\",\n",
    "    \"hubris.py\",\n",
    "    \"shield_analyzer.py\",\n",
    "    \"entropy_analyzer.py\",\n",
    "    \"lang_analyzers.py\",\n",
    "]\n",
    "\n",
    "missing = [f for f in required_files if not Path(f).exists()]\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing files: {missing}\")\n",
    "    print(\"Please ensure all toolsuite files are in the current directory.\")\n",
    "else:\n",
    "    print(\"‚úÖ All required files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding the Quadrant Model\n",
    "\n",
    "Prometheus maps codebases onto a 2D fitness chart:\n",
    "\n",
    "```\n",
    "                    HIGH RESILIENCE\n",
    "                          ‚îÇ\n",
    "         üèØ FORTRESS      ‚îÇ      üè∞ BUNKER\n",
    "    (Complex but          ‚îÇ    (Simple and\n",
    "     well-defended)       ‚îÇ     well-defended)\n",
    "                          ‚îÇ        ‚Üê IDEAL\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                          ‚îÇ\n",
    "         üíÄ DEATHTRAP     ‚îÇ      üè† GLASS HOUSE  \n",
    "    (Complex AND          ‚îÇ    (Simple but\n",
    "     undefended)          ‚îÇ     fragile)\n",
    "         ‚Üê DANGER         ‚îÇ\n",
    "                    LOW RESILIENCE\n",
    "```\n",
    "\n",
    "**Goal**: Move toward the BUNKER quadrant (top-right)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Analyzing a Local Repository\n",
    "\n",
    "Let's analyze a local codebase. You can point this at any Python project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - CHANGE THIS to your target repository\n",
    "TARGET_PATH = \".\"  # Current directory, or specify a path like \"/path/to/your/repo\"\n",
    "\n",
    "# For GitHub repos, you can use:\n",
    "# TARGET_PATH = \"pallets/flask\"  # Will clone from GitHub\n",
    "# TARGET_PATH = \"https://github.com/django/django\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Prometheus analysis\n",
    "!python prometheus.py \"{TARGET_PATH}\" --html prometheus_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the HTML report inline (if running in Jupyter)\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "if os.path.exists(\"prometheus_report.html\"):\n",
    "    # Try to display inline\n",
    "    display(IFrame(\"prometheus_report.html\", width=1000, height=800))\n",
    "else:\n",
    "    print(\"Report not generated. Check the output above for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Understanding the Scores\n",
    "\n",
    "Let's break down what the scores mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the most recent JSON report\n",
    "json_files = list(Path(\".\").glob(\"prometheus_*.json\"))\n",
    "if json_files:\n",
    "    latest_report = max(json_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading: {latest_report}\")\n",
    "\n",
    "    with open(latest_report) as f:\n",
    "        report = json.load(f)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROMETHEUS REPORT SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nüìä Quadrant: {report.get('quadrant', 'N/A')}\")\n",
    "    print(f\"\\n{report.get('fitness_verdict', 'N/A')}\")\n",
    "\n",
    "    scores = report.get(\"scores\", {})\n",
    "    print(f\"\\nüìà Complexity Score: {scores.get('complexity_score', 'N/A')}/100\")\n",
    "    print(f\"   Risk Level: {scores.get('complexity_risk', 'N/A')}\")\n",
    "\n",
    "    print(f\"\\nüõ°Ô∏è Resilience Score: {scores.get('resilience_score', 'N/A'):.1f}/100\")\n",
    "    print(f\"   Shield Rating: {scores.get('shield_rating', 'N/A')}\")\n",
    "else:\n",
    "    print(\"No JSON report found. Run the analysis first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed breakdown\n",
    "if \"report\" in dir():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPLEXITY BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    complexity = report.get(\"complexity_analysis\", {})\n",
    "    metrics = complexity.get(\"metrics\", {})\n",
    "\n",
    "    print(f\"\\nTotal LOC: {metrics.get('total_loc', 'N/A'):,}\")\n",
    "    print(f\"Avg Cyclomatic Complexity: {metrics.get('avg_cyclomatic', 'N/A'):.2f}\")\n",
    "    print(f\"Maintainability Index: {metrics.get('maintainability', 'N/A'):.1f}\")\n",
    "    print(f\"Code Entropy: {metrics.get('entropy', 'N/A'):.2f}\")\n",
    "\n",
    "    hotspots = complexity.get(\"hotspots\", [])\n",
    "    if hotspots:\n",
    "        print(f\"\\nüî• Top Hotspots ({len(hotspots)} total):\")\n",
    "        for h in hotspots[:5]:\n",
    "            print(f\"   - {h['file']}: {', '.join(h['issues'][:2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show resilience breakdown\n",
    "if \"report\" in dir():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESILIENCE BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    resilience = report.get(\"resilience_analysis\", {})\n",
    "    categories = resilience.get(\"category_scores\", {})\n",
    "\n",
    "    print(\"\\nCategory Scores:\")\n",
    "    for category, score in categories.items():\n",
    "        bar = \"‚ñà\" * int(score / 5) + \"‚ñë\" * (20 - int(score / 5))\n",
    "        print(f\"   {category:20} [{bar}] {score:.1f}%\")\n",
    "\n",
    "    vulns = resilience.get(\"vulnerabilities\", [])\n",
    "    if vulns:\n",
    "        print(f\"\\n‚ö†Ô∏è Vulnerabilities ({len(vulns)} found):\")\n",
    "        for v in vulns[:5]:\n",
    "            print(f\"   - [{v.get('severity', 'N/A')}] {v.get('message', 'N/A')}\")\n",
    "            print(f\"     File: {v.get('file', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Hubris - Detecting Resilience Theater\n",
    "\n",
    "Hubris analyzes whether resilience patterns are actually implemented correctly or are just \"theater\" - code that looks resilient but isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Hubris analysis\n",
    "!python hubris.py \"{TARGET_PATH}\" --html hubris_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display Hubris results\n",
    "hubris_files = list(Path(\".\").glob(\"hubris_*.json\"))\n",
    "if hubris_files:\n",
    "    latest_hubris = max(hubris_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading: {latest_hubris}\")\n",
    "\n",
    "    with open(latest_hubris) as f:\n",
    "        hubris = json.load(f)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"HUBRIS REPORT - RESILIENCE THEATER DETECTION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nüé≠ Verdict: {hubris.get('quadrant', 'N/A')}\")\n",
    "    print(f\"   Theater Ratio: {hubris.get('theater_ratio', 0):.2f}\")\n",
    "    print(\"   (Lower is better - 1.0 means patterns are correctly implemented)\")\n",
    "\n",
    "    print(\"\\nüìä Pattern Analysis:\")\n",
    "    print(f\"   Patterns Detected: {hubris.get('patterns_detected', 0)}\")\n",
    "    print(f\"   Correctly Implemented: {hubris.get('patterns_correct', 0)}\")\n",
    "    print(f\"   Partially Correct: {hubris.get('patterns_partial', 0)}\")\n",
    "    print(f\"   Cargo Cult (Theater): {hubris.get('patterns_cargo_cult', 0)}\")\n",
    "else:\n",
    "    print(\"No Hubris report found. Run the analysis first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Hubris Quadrants\n",
    "\n",
    "| Quadrant | Meaning | Action |\n",
    "|----------|---------|--------|\n",
    "| **SIMPLE** | Few patterns, but implemented correctly | Consider adding more resilience if needed |\n",
    "| **BATTLE_HARDENED** | Many patterns, implemented correctly | ‚úÖ Excellent! Maintain this standard |\n",
    "| **CARGO_CULT** | Many patterns, but incorrect/incomplete | ‚ö†Ô∏è Fix existing patterns before adding more |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Comparing Multiple Repositories\n",
    "\n",
    "You can compare multiple repositories side-by-side to see how they stack up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple repos (Gartner-style quadrant chart)\n",
    "# Uncomment and modify the repos you want to compare:\n",
    "\n",
    "REPOS_TO_COMPARE = [\n",
    "    # \"pallets/flask\",\n",
    "    # \"django/django\",\n",
    "    # \"fastapi/fastapi\",\n",
    "    # \"requests/requests\",\n",
    "]\n",
    "\n",
    "if REPOS_TO_COMPARE:\n",
    "    repos_str = \" \".join(REPOS_TO_COMPARE)\n",
    "    !python prometheus.py {repos_str} --html comparison.html\n",
    "else:\n",
    "    print(\"Add repos to REPOS_TO_COMPARE list and run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Understanding the Scoring Formulas\n",
    "\n",
    "Let's look at how scores are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculate_complexity_score(total_loc, avg_cyclo, maintainability, num_hotspots):\n",
    "    \"\"\"\n",
    "    Industry-calibrated complexity scoring.\n",
    "\n",
    "    Four equally-weighted factors (25 points each):\n",
    "    1. Size - Logarithmic penalty for large codebases\n",
    "    2. Cyclomatic - Cognitive load per function\n",
    "    3. Maintainability - Code quality index\n",
    "    4. Hotspots - Problem areas density\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. SIZE SCORE (0-25)\n",
    "    if total_loc < 5000:\n",
    "        size_score = 25\n",
    "    else:\n",
    "        size_score = max(5, 25 - (math.log10(total_loc / 5000) / math.log10(3)) * 5)\n",
    "\n",
    "    # 2. CYCLOMATIC SCORE (0-25)\n",
    "    if avg_cyclo <= 1.5:\n",
    "        cyclo_score = 25\n",
    "    elif avg_cyclo <= 3.0:\n",
    "        cyclo_score = 25 - (avg_cyclo - 1.5) * 7\n",
    "    else:\n",
    "        cyclo_score = max(0, 14 - (avg_cyclo - 3.0) * 6)\n",
    "\n",
    "    # 3. MAINTAINABILITY SCORE (0-25)\n",
    "    if maintainability >= 80:\n",
    "        maint_score = 25\n",
    "    elif maintainability >= 40:\n",
    "        maint_score = (maintainability - 40) / 40 * 25\n",
    "    else:\n",
    "        maint_score = 0\n",
    "\n",
    "    # 4. HOTSPOT SCORE (0-25)\n",
    "    hotspots_per_10k = (num_hotspots / max(1, total_loc)) * 10000\n",
    "    if hotspots_per_10k <= 0.5:\n",
    "        hotspot_score = 25\n",
    "    elif hotspots_per_10k <= 3.0:\n",
    "        hotspot_score = 25 - (hotspots_per_10k - 0.5) * 8\n",
    "    else:\n",
    "        hotspot_score = max(0, 5 - (hotspots_per_10k - 3.0) * 2)\n",
    "\n",
    "    return {\n",
    "        \"total\": size_score + cyclo_score + maint_score + hotspot_score,\n",
    "        \"size\": size_score,\n",
    "        \"cyclo\": cyclo_score,\n",
    "        \"maint\": maint_score,\n",
    "        \"hotspot\": hotspot_score,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example: Calculate for a hypothetical codebase\n",
    "print(\"Example Complexity Score Calculation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "example = calculate_complexity_score(\n",
    "    total_loc=50000, avg_cyclo=2.5, maintainability=72, num_hotspots=8\n",
    ")\n",
    "\n",
    "print(\"\\nInput: 50k LOC, 2.5 cyclomatic, 72 MI, 8 hotspots\")\n",
    "print(\"\\nBreakdown:\")\n",
    "print(f\"  Size Score:      {example['size']:.1f}/25\")\n",
    "print(f\"  Cyclomatic:      {example['cyclo']:.1f}/25\")\n",
    "print(f\"  Maintainability: {example['maint']:.1f}/25\")\n",
    "print(f\"  Hotspot:         {example['hotspot']:.1f}/25\")\n",
    "print(\"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(f\"  TOTAL:           {example['total']:.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Industry Benchmarks\n",
    "\n",
    "How do popular frameworks score? Here are some reference points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry benchmark data (based on actual analysis)\n",
    "benchmarks = [\n",
    "    {\n",
    "        \"name\": \"Flask\",\n",
    "        \"loc\": 14020,\n",
    "        \"complexity\": 56,\n",
    "        \"resilience\": 33,\n",
    "        \"quadrant\": \"GLASS HOUSE\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Django\",\n",
    "        \"loc\": 463361,\n",
    "        \"complexity\": 77,\n",
    "        \"resilience\": 31,\n",
    "        \"quadrant\": \"GLASS HOUSE\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FastAPI\",\n",
    "        \"loc\": 90615,\n",
    "        \"complexity\": 77,\n",
    "        \"resilience\": 31,\n",
    "        \"quadrant\": \"GLASS HOUSE\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Industry Benchmark Reference\")\n",
    "print(\"=\" * 70)\n",
    "print(\n",
    "    f\"{'Framework':<15} {'LOC':>10} {'Complexity':>12} {'Resilience':>12} {'Quadrant':<15}\"\n",
    ")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for b in benchmarks:\n",
    "    print(\n",
    "        f\"{b['name']:<15} {b['loc']:>10,} {b['complexity']:>12} {b['resilience']:>12} {b['quadrant']:<15}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nNote: Web frameworks are expected to be in GLASS HOUSE quadrant.\")\n",
    "print(\"They provide structure but don't implement application-level resilience.\")\n",
    "print(\"That's the application developer's responsibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Recommendations\n",
    "\n",
    "Based on your quadrant, here are recommended actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {\n",
    "    \"BUNKER\": {\n",
    "        \"status\": \"‚úÖ Ideal State\",\n",
    "        \"actions\": [\n",
    "            \"Maintain current practices\",\n",
    "            \"Consider if any resilience measures are redundant\",\n",
    "            \"Document patterns for team knowledge sharing\",\n",
    "        ],\n",
    "    },\n",
    "    \"FORTRESS\": {\n",
    "        \"status\": \"‚ö†Ô∏è Over-engineered but Safe\",\n",
    "        \"actions\": [\n",
    "            \"Reduce complexity while maintaining resilience\",\n",
    "            \"Refactor large functions and classes\",\n",
    "            \"Consider microservices if monolith is too large\",\n",
    "        ],\n",
    "    },\n",
    "    \"GLASS HOUSE\": {\n",
    "        \"status\": \"‚ö†Ô∏è Simple but Fragile\",\n",
    "        \"actions\": [\n",
    "            \"Add timeouts to all network calls\",\n",
    "            \"Implement retry with exponential backoff\",\n",
    "            \"Add structured logging and metrics\",\n",
    "            \"Consider circuit breakers for external dependencies\",\n",
    "        ],\n",
    "    },\n",
    "    \"DEATHTRAP\": {\n",
    "        \"status\": \"üö® High Risk - Immediate Action Required\",\n",
    "        \"actions\": [\n",
    "            \"STOP adding features until resilience improves\",\n",
    "            \"Add basic error handling to all I/O operations\",\n",
    "            \"Implement health checks and monitoring\",\n",
    "            \"Refactor highest-complexity modules first\",\n",
    "            \"Consider a partial rewrite if technical debt is too high\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Show recommendations based on the analysis\n",
    "if \"report\" in dir():\n",
    "    quadrant = report.get(\"quadrant\", \"UNKNOWN\")\n",
    "    if quadrant in recommendations:\n",
    "        rec = recommendations[quadrant]\n",
    "        print(f\"Recommendations for {quadrant}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"\\nStatus: {rec['status']}\")\n",
    "        print(\"\\nRecommended Actions:\")\n",
    "        for i, action in enumerate(rec[\"actions\"], 1):\n",
    "            print(f\"  {i}. {action}\")\n",
    "else:\n",
    "    print(\"Run an analysis first to get personalized recommendations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Library Mode\n",
    "\n",
    "If you're analyzing a library (not an application), use library mode for adjusted scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library mode - adjusts scoring expectations\n",
    "# Libraries don't need timeouts/retries - they expose APIs for users to implement them\n",
    "\n",
    "LIBRARY_PATH = \".\"  # Change to your library path\n",
    "\n",
    "# Uncomment to run:\n",
    "# !python prometheus.py \"{LIBRARY_PATH}\" --library --html library_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Export and Share\n",
    "\n",
    "Export your analysis for sharing with your team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated reports\n",
    "import glob\n",
    "\n",
    "print(\"Generated Reports:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for pattern in [\"*.html\", \"*_*.json\"]:\n",
    "    files = glob.glob(pattern)\n",
    "    for f in sorted(files):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"  üìÑ {f} ({size:,} bytes)\")\n",
    "\n",
    "print(\"\\nüí° Share the HTML files for interactive viewing.\")\n",
    "print(\"   JSON files contain raw data for further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Quick Reference\n",
    "\n",
    "### Command Line Usage\n",
    "\n",
    "```bash\n",
    "# Single repo analysis\n",
    "python prometheus.py /path/to/repo\n",
    "python prometheus.py owner/repo  # GitHub shorthand\n",
    "\n",
    "# Multi-repo comparison\n",
    "python prometheus.py repo1 repo2 repo3 --compare\n",
    "\n",
    "# Library mode (adjusted scoring)\n",
    "python prometheus.py mylib --library\n",
    "\n",
    "# Hubris (resilience theater detection)\n",
    "python hubris.py /path/to/repo\n",
    "```\n",
    "\n",
    "### Score Interpretation\n",
    "\n",
    "| Score Range | Complexity | Resilience |\n",
    "|-------------|------------|------------|\n",
    "| 80-100 | Excellent | ADAMANTINE |\n",
    "| 60-79 | Good | STEEL |\n",
    "| 40-59 | Moderate | BRONZE |\n",
    "| 20-39 | Poor | WOOD |\n",
    "| 0-19 | Critical | PAPER |\n",
    "\n",
    "### Shield Ratings Explained\n",
    "\n",
    "- **ADAMANTINE**: Netflix/Google-level resilience (rare)\n",
    "- **STEEL**: Production-ready, well-defended\n",
    "- **BRONZE**: Adequate for most applications\n",
    "- **WOOD**: Minimal protection, improvement needed\n",
    "- **PAPER**: Essentially undefended, high risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the Prometheus Toolsuite tutorial. You now know how to:\n",
    "\n",
    "1. ‚úÖ Analyze codebase complexity and resilience\n",
    "2. ‚úÖ Interpret quadrant charts and scores\n",
    "3. ‚úÖ Detect resilience theater with Hubris\n",
    "4. ‚úÖ Compare multiple repositories\n",
    "5. ‚úÖ Understand industry benchmarks\n",
    "\n",
    "**Next steps:**\n",
    "- Run analysis on your production codebases\n",
    "- Set up CI/CD integration for continuous monitoring\n",
    "- Share results with your team for prioritization discussions\n",
    "\n",
    "---\n",
    "\n",
    "*Prometheus Toolsuite - Because you can't improve what you can't measure.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
