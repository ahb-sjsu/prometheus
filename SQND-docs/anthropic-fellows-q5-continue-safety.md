# How likely are you to continue working on AI safety after the Fellows program?

Certain. This isn't a career pivot—it's where I've already been heading.

I've spent two years building alignment verification frameworks without institutional support or funding because I believe the problem is real and solvable. The fellowship would accelerate work I'm already committed to, not introduce me to a field I might later abandon.

The questions I'm investigating—can we measure alignment failures? can we build falsifiable safety guarantees?—don't have expiration dates. Whether at Anthropic, another safety-focused organization, or continuing independent research, I'll be working on these problems. The only question is how effectively.
