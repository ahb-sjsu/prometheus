# Letter to Foresight Institute

**To:** Foresight Institute Grants Team
**From:** Andrew H. Bond, Ph.D. Candidate
**Date:** January 2026
**Re:** Proposal for Institute for AI Safety & Philosophy Engineering

---

Dear Foresight Institute Grants Team,

I am writing to propose the establishment of an **Institute for AI Safety & Philosophy Engineering (IASPE)**—a research organization dedicated to developing falsifiable, empirically testable frameworks for AI alignment verification. I believe this work aligns strongly with Foresight's mission to reduce existential risk from advanced AI, and I am seeking funding to scale what has been a productive independent research program into an institution capable of broader impact.

## The Problem

Current approaches to AI alignment often rest on unfalsifiable claims. We debate whether systems are "truly aligned" without agreed-upon methods for testing alignment empirically. This leaves deployment decisions dependent on intuition rather than measurement. We need alignment verification that works like engineering: declare invariances, test them, produce counterexamples when they fail.

## The Solution: Philosophy Engineering

I have developed a research program that transforms ethical and normative claims into testable engineering properties. The core insight: we cannot verify alignment directly, but we can *measure alignment failures* through symmetry violations, incoherence detection, and adversarial probing.

**Key contributions to date:**

- **The AI Safety Stack**: An 8-layer architecture for ethics verification, from foundational pragmatism through machine-checkable specifications to deployment decisions
- **Bond Invariance Principle (BIP)**: Falsifiability mechanism testing whether AI judgment maintains coherence under semantic perturbation, with 10,500+ adversarial test cases
- **SQND (Stratified Quantum Normative Dynamics)**: Empirical measurement of moral reasoning structure using symmetry-based coherence detection, with extensive experimental validation (Bell tests, contextuality experiments, holonomy measurements)
- **DEME 2.0**: Three-layer safety architecture for scalable ethical oversight (submitted to Nature Machine Intelligence)
- **ErisML**: Formal specification language for governed agents (submitted to IEEE Transactions on AI)

All frameworks are implemented in working code: https://github.com/ahb-sjsu/erisml-lib

## Why an Institute?

This work has reached the limits of what one researcher can accomplish. An institute would enable:

1. **Scaled experimentation**: Systematic evaluation across model families, larger adversarial test suites, rigorous statistical characterization of alignment failures
2. **Tool development**: Production-quality verification systems that labs and deployers can actually use
3. **Training**: Graduate students and researchers in philosophy engineering methods
4. **Collaboration**: Partnerships with frontier labs (I am currently applying to the Anthropic Fellows Program) and other safety organizations
5. **Open infrastructure**: Public benchmarks and datasets for alignment verification

## Alignment with Foresight Focus Areas

IASPE directly addresses several Foresight priorities:

- **AI for Security**: The Bond Index provides concrete metrics for identifying exploitable inconsistencies in AI reasoning—security vulnerabilities in the normative layer
- **Decentralized & Cooperative AI**: ErisML and DEME enable formal specification of norms for multi-agent systems, supporting safe multipolar AI scenarios
- **AI for Science & Epistemics**: SQND experimental protocols are reproducible scientific methods for characterizing AI behavior; the Epistemic Invariance Principle addresses objectivity in AI systems

## Proposed Use of Funds

**Year 1 ($150,000-250,000):**
- Dedicated compute for scaled SQND experiments across multiple model families
- Research assistant support (graduate students)
- Infrastructure: Bond Index calibration suite, public benchmarks
- Travel for collaboration with frontier labs and safety organizations

**Year 2+ (contingent on results):**
- Additional researchers
- Production tool development
- Workshop/training programs

I am based in the Bay Area (Sonoma State University / San Jose State University) and would welcome the opportunity to work from Foresight's San Francisco node, which would provide valuable community integration and collaboration opportunities.

## Why Now?

The window for establishing alignment verification standards is closing. As AI systems become more capable, the cost of alignment failures increases. Falsifiable safety guarantees need to be developed *before* they're urgently needed, not after. The frameworks exist—they need resources to scale.

## About Me

I am a faculty member at Sonoma State University and San Jose State University, where I teach computer science and advise graduate research. I hold an M.S. in Software Engineering from SJSU and am an IEEE Senior Member. My AI safety research program has produced multiple papers currently under review at top venues and extensive experimental results demonstrating the viability of symmetry-based alignment verification.

- CV: [attached]
- Research: https://github.com/ahb-sjsu/erisml-lib
- Experiments: https://github.com/ahb-sjsu/prometheus/tree/main/SQND-docs
- Academic: https://www.sjsu.edu/people/andrew.bond/

## Request

I am requesting an initial grant of **$150,000-250,000** to establish IASPE and execute Year 1 objectives. I would welcome the opportunity to discuss this proposal further and explore how Philosophy Engineering might contribute to Foresight's mission.

Thank you for your consideration.

Respectfully,

**Andrew H. Bond**
Lecturer, Department of Computer Science, Sonoma State University
Faculty, Department of Computer Science and Engineering, San Jose State University
ahbond@sonoma.edu | agi.hpc@gmail.com

---

## Appendix: Key Resources

- AI Safety Stack: https://github.com/ahb-sjsu/erisml-lib/blob/main/AI_SAFETY_STACK.md
- ErisML & DEME Implementation: https://github.com/ahb-sjsu/erisml-lib
- SQND Experiments & Results: https://github.com/ahb-sjsu/prometheus/tree/main/SQND-docs
- SQND-Probe Measurement Tool: https://github.com/ahb-sjsu/sqnd-probe
- AGI-HPC Infrastructure: https://github.com/ahb-sjsu/agi-hpc
